{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ],
      "metadata": {
        "id": "Ws52yb5rn6tR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   This notebook sets up and trains a neural network to classify images into one of two categories: handwritten 4s and handwritten 9s.\n"
      ],
      "metadata": {
        "id": "1w4pUW5lrLln"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libaries"
      ],
      "metadata": {
        "id": "ZFiMUmrtnmsQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKbFGcEdnd2b",
        "outputId": "5188588e-20d0-4153-ca47-830b38820661"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras_tuner in /usr/local/lib/python3.10/dist-packages (1.4.7)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (24.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (2.31.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (1.0.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_tuner"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import requests\n",
        "import keras\n",
        "import keras_tuner\n",
        "from keras import layers, regularizers\n",
        "from keras.optimizers.legacy import Adam\n",
        "from keras.callbacks import EarlyStopping, TensorBoard\n",
        "import json\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "QyJ110I8njHq"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading in MNIST from Keras"
      ],
      "metadata": {
        "id": "IMj1kvZ2oRfV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data set for this notebook will consist of handwritten digits imported from Keras data set."
      ],
      "metadata": {
        "id": "2HWGsTQFxpVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist"
      ],
      "metadata": {
        "id": "LV4Z0ouUoS6p"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_X, y_train), (test_X, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "pqiGwn5epblw"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The MNIST dataset comes pre split into training and test sets."
      ],
      "metadata": {
        "id": "XZFkB4Mr0ZmO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter data"
      ],
      "metadata": {
        "id": "uygIVKV8rWyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to filter the data set to include only images of the digits 4 and 9."
      ],
      "metadata": {
        "id": "ajeTwdCp047O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_train = np.where((y_train == 4) | (y_train == 9))\n",
        "filtered_test = np.where((y_test == 4) | (y_test == 9))"
      ],
      "metadata": {
        "id": "OjUTq9skrXJ2"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X, y_train = train_X[filtered_train], y_train[filtered_train]\n",
        "test_X, y_test = test_X[filtered_test], y_test[filtered_test]"
      ],
      "metadata": {
        "id": "aS2YksHorbpd"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have reduced our data set to contain what is relevant to this notebook."
      ],
      "metadata": {
        "id": "kblYU69O1LpU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## View shape and images"
      ],
      "metadata": {
        "id": "Kr3HVMsmvdzf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Look at the shapes of our training and test sets and visualize some of the images."
      ],
      "metadata": {
        "id": "1rVBTCjm1k3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('X_train: ' + str(train_X.shape))\n",
        "print('Y_train: ' + str(y_train.shape))\n",
        "print('X_test:  '  + str(test_X.shape))\n",
        "print('Y_test:  '  + str(y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDqUIpHOritC",
        "outputId": "7a83706c-e9a9-4526-f6ef-108353998d64"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (11791, 28, 28)\n",
            "Y_train: (11791,)\n",
            "X_test:  (1991, 28, 28)\n",
            "Y_test:  (1991,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "  plt.subplot(330 + 1 + i)\n",
        "  plt.imshow(train_X[i], cmap=plt.get_cmap('gray'))\n",
        "  plt.show()\n",
        "  print(y_train[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "-V3TI076rkwx",
        "outputId": "dbc5699d-1237-4f40-b55a-84e29a3e0ab1"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After looking at the data, we can now reshape and normalize the images to prepare them for training our neural network."
      ],
      "metadata": {
        "id": "ysk4lyH51tcK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Flatten images"
      ],
      "metadata": {
        "id": "oocTfA_pr-I1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now reshape each image into a 1D vector."
      ],
      "metadata": {
        "id": "kplgOT_C2HMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlEz4fwurmzX",
        "outputId": "16a715dc-2811-4f37-bd86-a76480540580"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11791, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_X.reshape(train_X.shape[0], -1)"
      ],
      "metadata": {
        "id": "3nE5G1Cbrt-9"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBu1FIhEryHc",
        "outputId": "639f2548-0ca6-4084-f18f-753419d4bce7"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11791, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = test_X.reshape(test_X.shape[0], -1)"
      ],
      "metadata": {
        "id": "ajZtH8fYrzlh"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMZC57Errz4w",
        "outputId": "a9bafdd2-9708-4177-e5f1-dd4b18982757"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1991, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshaping the 2D image into a 1D vector makes it suitable to input into our neural network."
      ],
      "metadata": {
        "id": "ODmHxB6d2SEi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalization"
      ],
      "metadata": {
        "id": "mi_A5JrhruXN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize the features (the pixels) of image data."
      ],
      "metadata": {
        "id": "qEd2owjR20lA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_norm = X_train / 255\n",
        "X_test_norm = X_test / 255"
      ],
      "metadata": {
        "id": "2NUX5d7-r1aX"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By dividing all pixels by the max pixel magnitude 255, we get values that are between [0, 1]."
      ],
      "metadata": {
        "id": "FodJnqsN3Dvq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build model"
      ],
      "metadata": {
        "id": "wdzG8tywrgyS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define and build our neural network model."
      ],
      "metadata": {
        "id": "jhZZmPjZ3Qsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model(units, num_layers, activation, lr, l2):\n",
        "    model_layers = [\n",
        "        layers.Dense(units, activation=activation, kernel_regularizer=regularizers.L2(l2=l2), kernel_initializer=keras.initializers.HeNormal())\n",
        "        ] * num_layers\n",
        "    model_layers += [layers.Dense(10)]\n",
        "    model = keras.Sequential(model_layers)\n",
        "    model.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'], optimizer=Adam(learning_rate=lr))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "RVDvIj_PsUaK"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "    units = hp.Choice(\"units\", [256, 512])\n",
        "    activation = \"relu\"\n",
        "    lr = hp.Float(\"lr\", min_value=1e-5, max_value=1e-1, sampling=\"log\")\n",
        "    l2 = hp.Float(\"l2\", min_value=1e-5, max_value=1e-1, sampling=\"log\")\n",
        "    num_layers = hp.Choice(\"num_layers\", [2, 3, 4])\n",
        "\n",
        "    model = define_model(units=units, num_layers=num_layers, activation=activation, lr=lr, l2=l2)\n",
        "    return model"
      ],
      "metadata": {
        "id": "7ZUjc2zxsU_j"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The define_model function builds a Keras model with the same layer sizes and L2 regularization. The build_model function is passed to the tuner to find the best hyperparameters."
      ],
      "metadata": {
        "id": "KytOpeoK56rB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92NL0QjOsXQw",
        "outputId": "cc87148f-0705-44bb-c299-310c91630ab8"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameter tuning with Bayesian Optimization"
      ],
      "metadata": {
        "id": "RFsMW1dZt3WZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initializes the tuner object."
      ],
      "metadata": {
        "id": "vHQ3ZGEt6BKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = keras_tuner.BayesianOptimization(\n",
        "    hypermodel=build_model,\n",
        "    objective=\"val_loss\",\n",
        "    max_trials=8,\n",
        "    executions_per_trial=1,\n",
        "    overwrite=False,\n",
        "    directory=\"/content/drive/MyDrive/image_classification\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_dw2IJSsZKc",
        "outputId": "a850671c-2edb-4ad3-ea90-fba2ccd28332"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reloading Tuner from /content/drive/MyDrive/image_classification/untitled_project/tuner0.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [EarlyStopping(monitor=\"val_loss\", patience=2, restore_best_weights=True, start_from_epoch=4)]"
      ],
      "metadata": {
        "id": "h2WLFotDsc20"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tuner is set to optimize the model based on validation loss, and early stopping is used to check whether the accuracy is still increasing."
      ],
      "metadata": {
        "id": "YktFUFUe7FV6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model and Evaluation"
      ],
      "metadata": {
        "id": "aBPdz0PUuLnj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the tuner to search for the best hyperparameters, and then evaluate the best model on the test data."
      ],
      "metadata": {
        "id": "u6oyYfpX8p6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(\n",
        "    X_train_norm,\n",
        "    y_train,\n",
        "    epochs=8,\n",
        "    verbose=1,\n",
        "    validation_data=(X_test_norm, y_test),\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "id": "9fYUJuYoseMw"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.results_summary(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ay1a4WRDtMtj",
        "outputId": "6a630c1b-7bd2-4525-e1f2-8603f51c63ab"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in /content/drive/MyDrive/image_classification/untitled_project\n",
            "Showing 5 best trials\n",
            "Objective(name=\"val_loss\", direction=\"min\")\n",
            "\n",
            "Trial 0 summary\n",
            "Hyperparameters:\n",
            "units: 512\n",
            "lr: 0.0007386457755165143\n",
            "l2: 0.00019497217747107664\n",
            "num_layers: 4\n",
            "Score: 0.05632062628865242\n",
            "\n",
            "Trial 3 summary\n",
            "Hyperparameters:\n",
            "units: 512\n",
            "lr: 0.0019647765700888434\n",
            "l2: 0.0016714322755079418\n",
            "num_layers: 4\n",
            "Score: 0.06839607656002045\n",
            "\n",
            "Trial 4 summary\n",
            "Hyperparameters:\n",
            "units: 256\n",
            "lr: 0.01775305777697317\n",
            "l2: 1.946571389816994e-05\n",
            "num_layers: 2\n",
            "Score: 0.0764264166355133\n",
            "\n",
            "Trial 6 summary\n",
            "Hyperparameters:\n",
            "units: 256\n",
            "lr: 5.401659824126282e-05\n",
            "l2: 5.5808138488127885e-05\n",
            "num_layers: 2\n",
            "Score: 0.08700831979513168\n",
            "\n",
            "Trial 2 summary\n",
            "Hyperparameters:\n",
            "units: 256\n",
            "lr: 0.01885595480835371\n",
            "l2: 0.000341579004974261\n",
            "num_layers: 2\n",
            "Score: 0.09689763933420181\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trial_num = \"0\"\n",
        "with open(f\"/content/drive/MyDrive/image_classification/untitled_project/trial_{trial_num}/trial.json\", \"r\") as f:\n",
        "    trial = json.load(f)\n",
        "hp = trial[\"hyperparameters\"][\"values\"]\n",
        "model = define_model(units=hp[\"units\"], num_layers=hp[\"num_layers\"], activation=\"relu\", lr=hp[\"lr\"],\n",
        "                     l2=hp[\"l2\"])\n",
        "model.load_weights(f\"/content/drive/MyDrive/image_classification/untitled_project/trial_{trial_num}/checkpoint\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQECMd8XtNAZ",
        "outputId": "00dee96d-25a4-4a8f-efdc-16d0f9805725"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7a5cb6988940>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.argmax(model.predict(X_test_norm), axis=1)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "accuracy = sum(y_pred == y_test) / len(y_test)\n",
        "print(accuracy)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIiPKOGctkJG",
        "outputId": "fd4bd6d5-341d-4bf8-93b7-beb4495da7e1"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 4ms/step\n",
            "0.9904570567553993\n",
            "[[ 972   10]\n",
            " [   9 1000]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best model was number 0 so it was used to make our predictions. Our model had an accuracy of 99.05% when categorizing handwritten 4s and 9s."
      ],
      "metadata": {
        "id": "m-msw8TA86qQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion"
      ],
      "metadata": {
        "id": "s0kTuYw8u_Zj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Using the MNIST dataset, we built and trained a neural network to categorize handwritten 4s and 9s. We optimized our model by finding the best hyperparameters and then applying the model to our test set. This resulted in a 99.05% accuracy, showing the effectiveness of the model."
      ],
      "metadata": {
        "id": "aOLJCEac-hFI"
      }
    }
  ]
}